{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SIF+UKFNN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python376jvsc74a57bd0d48c7bdae873f1c2f85b053c005cb0467203ab6c325afd72fd70f1bdbbf87920",
      "display_name": "Python 3.7.6 64-bit ('base': conda)"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "source": [
        "# Tuning A Neural Network Using SIF vs KF (Regression Task)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtodN43bsuSt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1c0f43a-c677-449c-8246-99ae62cfafa4"
      },
      "source": [
        "# Installing necessary libraries\n",
        "!pip install filterpy\n",
        "\n",
        "# Importing global modules\n",
        "from pprint import pformat\n",
        "import numpy as np\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from filterpy.kalman import KalmanFilter, UnscentedKalmanFilter, MerweScaledSigmaPoints, unscented_transform\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "import math\n",
        "import os\n",
        "import time\n",
        "import logging\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.callbacks import Callback\n",
        "#import matlab.engine\n",
        "from io import StringIO\n",
        "import pdb\n",
        "import tensorflow as tf\n",
        "import random\n",
        "#eng = matlab.engine.start_matlab()\n",
        "\n",
        "# Importing local modules\n",
        "import ukf\n",
        "import utility"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: filterpy in /Users/onursurucu/opt/anaconda3/lib/python3.7/site-packages (1.4.5)\n",
            "Requirement already satisfied: numpy in /Users/onursurucu/opt/anaconda3/lib/python3.7/site-packages (from filterpy) (1.19.5)\n",
            "Requirement already satisfied: scipy in /Users/onursurucu/opt/anaconda3/lib/python3.7/site-packages (from filterpy) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /Users/onursurucu/opt/anaconda3/lib/python3.7/site-packages (from filterpy) (3.3.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/onursurucu/opt/anaconda3/lib/python3.7/site-packages (from matplotlib->filterpy) (0.10.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /Users/onursurucu/opt/anaconda3/lib/python3.7/site-packages (from matplotlib->filterpy) (7.0.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/onursurucu/opt/anaconda3/lib/python3.7/site-packages (from matplotlib->filterpy) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/onursurucu/opt/anaconda3/lib/python3.7/site-packages (from matplotlib->filterpy) (2.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /Users/onursurucu/opt/anaconda3/lib/python3.7/site-packages (from matplotlib->filterpy) (2.8.1)\n",
            "Requirement already satisfied: six in /Users/onursurucu/opt/anaconda3/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->filterpy) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /Users/onursurucu/opt/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->filterpy) (46.0.0.post20200309)\n",
            "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
            "You should consider upgrading via the '/Users/onursurucu/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "source": [],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tracking of weights by epoch\n",
        "class EpochInfoTracker(Callback):\n",
        "    def __init__(self):\n",
        "        self.weights_history = []                       # Tracking the weights in each epochs\n",
        " \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        weights_vec = get_weights_vector(self.model)\n",
        "        self.weights_history.append(weights_vec)\n",
        " \n",
        "# Class for keeping the necessary parameters\n",
        "class Params:\n",
        "    pass"
      ]
    },
    {
      "source": [],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#--------------Initialization of the parameters------------\n",
        "params = Params()\n",
        "params.epochs = 1200\n",
        "params.train_series_length = 500\n",
        "params.test_series_length = 1000\n",
        "params.mg_tau = 30\n",
        "params.window_size = 12    # M\n",
        "params.ukf_dt = 0.1\n",
        "params.alpha, params.beta, params.kappa = 1, 2, 1  # Worked well\n",
        "# params.alpha, params.beta, params.kappa = 0.001, 2, 1\n",
        "params.Q_var = 0.001\n",
        "params.R_var = 0.001\n",
        "\n",
        "# To make training data and related variables accessible across functions\n",
        "params.train_ukf_ann = True\n",
        "params.X_data = None\n",
        "params.y_data = None\n",
        "params.hxw_model = None\n",
        "params.curr_idx = 0\n",
        "\n",
        "\n",
        "def measurement_func(w, x):\n",
        "    hxw_model = params.hxw_model\n",
        "    qq = np.asarray(w)\n",
        "    ww = np.reshape(qq, (13))\n",
        "    set_weights(hxw_model, ww)\n",
        "    # Reshape needed to feed x as 1 sample to ANN model\n",
        "    hxw = hxw_model.predict(x.reshape(1, len(x)))\n",
        "    hxw = hxw.flatten()  # Flatten to make shape = (1,)\n",
        "    return hxw\n",
        "\n",
        "\n",
        "def fw(w, dt=None):\n",
        "    return w    # Identity\n",
        "\n",
        "\n",
        "def hw(w):\n",
        "    x = params.X_data[params.curr_idx]\n",
        "    hxw = measurement_func(w, x)\n",
        "    return hxw\n",
        "\n",
        "# Create ukf using pykalman\n",
        "def create_ukf(Q, R, dt, w_init, P_init):\n",
        "    M = w_init.shape[0]\n",
        "\n",
        "    points = MerweScaledSigmaPoints(M, params.alpha, params.beta, params.kappa)\n",
        "\n",
        "    ukf = UnscentedKalmanFilter(\n",
        "        dim_x=M, dim_z=1, dt=dt, fx=fw, hx=hw, points=points)\n",
        "    ukf.x = w_init\n",
        "    ukf.P = P_init\n",
        "    ukf.R = R\n",
        "    ukf.Q = Q\n",
        "\n",
        "    return ukf\n",
        "\n",
        "# Create ukf using ukf.py\n",
        "def create_my_ukf(Q, R, dt, w_init, P_init):\n",
        "    my_ukf = ukf.UnscentedKalmanFilter(\n",
        "        fw, hw, R, Q, w_init, P_init, params.alpha, params.beta, params.kappa)\n",
        "    return my_ukf\n",
        "\n",
        "# Reshape the dataset as: (batchsize, window_size)\n",
        "def prepare_dataset(series, M, stride):\n",
        "    X, y = [], []\n",
        "    for i in range(0, len(series) - M - 1, stride):\n",
        "        window = series[i:(i + M)]  #\n",
        "        X.append(window)\n",
        "        y.append(series[i + M])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "def evaluate_neural_nets(sgd_ann, ukf_ann, window, use_train_series=False, train_series=None):\n",
        "    if use_train_series:\n",
        "        X_data, y_data = params.X_data, params.y_data\n",
        "        series = train_series\n",
        "        sample_len = params.train_series_length\n",
        "        title = \"Train series (true vs. predicted)\"\n",
        "    else:\n",
        "        sample_len = params.test_series_length\n",
        "        series = utility.mackey_glass(sample_len=sample_len, tau=params.mg_tau)\n",
        "        series = np.array(series[0]).reshape((sample_len))\n",
        "        X_data, y_data = prepare_dataset(series, window, stride=1)\n",
        "        title = \"Test series (true vs. predicted)\"\n",
        "\n",
        "    sgd_pred, sgd_self_pred = utility.predict_series(\n",
        "        sgd_ann, X_data, sample_len, window)\n",
        "    ukf_pred, ukf_self_pred = utility.predict_series(\n",
        "        ukf_ann, X_data, sample_len, window)\n",
        "\n",
        "    utility.plot(range(sample_len), series, title=title, label='True series')\n",
        "   # utility.plot(range(sample_len), sgd_pred, new_figure=False, label='SGD ANN prediction (based on true windows)')\n",
        "    utility.plot(range(sample_len), ukf_pred, new_figure=False,\n",
        "                 label='SIF ANN prediction')\n",
        "    if not use_train_series:\n",
        "        preds = ukf_ann.predict(X_data)\n",
        "        mse = mean_squared_error(y_data, preds)\n",
        "        print(\"The Test MSE is: \", mse)\n",
        "\n",
        "    # utility.plot(range(sample_len), y_self_pred_series, new_figure=False,\n",
        "    #              label='Predicted test series (rolling prediction: no true vals used)')\n",
        "\n",
        "\n",
        "# Create a simple feedforward neural network \n",
        "def create_neural_net(M):\n",
        "\n",
        "    # Build a simple neural network\n",
        "    ann = Sequential()\n",
        "    ann.add(Dense(1, input_dim=M, activation='tanh'))\n",
        "    ann.compile(optimizer='sgd', loss='mse')\n",
        "\n",
        "    # Print out the summary of the model\n",
        "    ann.summary()\n",
        "\n",
        "    return ann\n",
        "\n",
        "\n",
        "def get_weights_vector(model):\n",
        "    weights = model.get_weights()\n",
        "    # logging.info(weights)\n",
        "    weights_vec = []\n",
        "    for w_mat in weights:\n",
        "        weights_vec.extend(w_mat.reshape(w_mat.size))\n",
        "\n",
        "    weights_vec = np.array(weights_vec)\n",
        "    return weights_vec\n",
        "\n",
        "\n",
        "def set_weights(model, weights_vec):\n",
        "    prev_weights = model.get_weights()\n",
        "    # logging.info(prev_weights)\n",
        "    new_weights = []\n",
        "    start = 0\n",
        "\n",
        "    for prev_w_mat in prev_weights:\n",
        "        end = start + prev_w_mat.size\n",
        "        new_w_mat = np.array(weights_vec[start: end]).reshape(prev_w_mat.shape)\n",
        "        new_weights.append(new_w_mat)\n",
        "        start = end\n",
        "\n",
        "    model.set_weights(new_weights)\n",
        "\n",
        "\n",
        "def test_weights_functions():\n",
        "    ann = create_neural_net(10)\n",
        "    prev_weights = ann.get_weights()\n",
        "    vec = get_weights_vector(ann)\n",
        "    # vec = [elem + 1 for elem in vec]\n",
        "\n",
        "    ann2 = create_neural_net(10)\n",
        "    set_weights(ann2, vec)\n",
        "    post_weights = ann2.get_weights()\n",
        "\n",
        "    for w_mat1, w_mat2 in zip(prev_weights, post_weights):\n",
        "        assert np.array_equal(w_mat1, w_mat2)\n",
        "\n",
        "    logging.info(prev_weights)\n",
        "    logging.info(post_weights)"
      ]
    },
    {
      "source": [
        "Initialization of the functions and essential parameters before exxecution of the algorithm."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgtTGKXP8Ecj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bb04364e-6760-434a-f113-e518ca758762",
        "tags": [
          "outputPrepend"
        ]
      },
      "source": [
        "def main():\n",
        "    #utility.setup_logging('output')\n",
        "    #logging.info('Experiment parameters below')\n",
        "    #logging.info('\\n{}'.format(pformat(params.__dict__)))\n",
        "\n",
        "    # test_weights_functions()\n",
        "    # assert False\n",
        "\n",
        "    # -------------------------------------------\n",
        "    # Setting parameters\n",
        "\n",
        "    # Known paramaters are hx function (neural net), Q, R, w_init\n",
        "    # No. of state variables = no. of weights in neural net\n",
        "    # No. of measurement variables = D = 1 (y)\n",
        "\n",
        "    \n",
        "    window = params.window_size                                                 # Setting window size\n",
        "    dt = 0.01                                                                   # Setting learning rate\n",
        "    n_samples = params.train_series_length                                      # Setting batch size\n",
        "\n",
        "    # -------------------------------------------\n",
        "    # Generating data\n",
        "    X_series = utility.mackey_glass(                                            # Generating the dataset (Mackey Glass)\n",
        "        sample_len=n_samples, tau=params.mg_tau, n_samples=window)\n",
        "    X_series = np.array(X_series[0]).reshape((n_samples))\n",
        "\n",
        "    params.X_data, params.y_data = prepare_dataset(X_series, window, stride=1)  # Reshaping dataset for a regression task\n",
        "   # params.X_data, params.y_data = xx , yy\n",
        "    # Create ANN, get its initial weights\n",
        "    params.hxw_model = create_neural_net(window)                                # Create neural net model\n",
        "    w_init = get_weights_vector(params.hxw_model)                               # Get weights from neural nets\n",
        "    num_weights = w_init.shape[0]                                               \n",
        "\n",
        "\n",
        "#---------------------------Filter Parameters-----------------------\n",
        "\n",
        "    #-----------------UKF Parameter------------------\n",
        "    # Initial values of covariance matrix of state variables (MxM)             \n",
        "    P_init = 0.1 * np.eye(num_weights)  \n",
        "    # Process noise covariance matrix (MxM)\n",
        "    Q = params.Q_var * np.eye(num_weights)\n",
        "    R = np.array([[params.R_var]])  # Measurement noise covariance matrix (DxD)\n",
        "\n",
        "    sgd_ann = create_neural_net(window)\n",
        "    # Same starting point as the UKF_ANN\n",
        "    sgd_ann.set_weights(params.hxw_model.get_weights())\n",
        "\n",
        "    ukf_ann = create_neural_net(window)\n",
        "    testann = create_neural_net(window)\n",
        "\n",
        "    # Same starting point as the UKF_ANN\n",
        "    ukf_ann.set_weights(params.hxw_model.get_weights())\n",
        "\n",
        "    z_true_series = params.y_data\n",
        "    num_iter = params.epochs * len(z_true_series)\n",
        "\n",
        "    # 2 Kalman filter implementations to compare (from filterpy and my custom impl)\n",
        "    ukf_filter = create_ukf(Q, R, dt, w_init, P_init)                           # Initialization of the UKF\n",
        "    my_ukf = create_my_ukf(Q, R, dt, w_init, P_init)                            # Initialiation of the SIF\n",
        "\n",
        "    # Pre-allocate output variables\n",
        "    ukf_w = np.zeros((num_weights, params.epochs))\n",
        "    my_ukf_w = np.zeros((num_weights, params.epochs))\n",
        "    ukf_train_mse = np.zeros(params.epochs)\n",
        "    my_ukf_train_mse = np.zeros(params.epochs)\n",
        "    sgd_train_mse = np.zeros(params.epochs)\n",
        "\n",
        "    # SIF Initalize Variables\n",
        "    x = w_init\n",
        "    n = x.shape[0]  # Number of States\n",
        "    m = z_true_series.shape[0]\n",
        "    #delta = [[0.09], [9], [0.9]]\n",
        "    delta = np.random.uniform(low=0.0009, high=0.9, size=(487,))\n",
        "    sat = np.zeros((m, m))\n",
        "    C = np.ones((487,13))\n",
        "    P = P_init\n",
        "    innovA = np.zeros((m, 1))\n",
        "\n",
        "    N = len(x)\n",
        "    w = np.zeros((x.shape))\n",
        "    eta = 0.01\n",
        "    x = get_weights_vector(ukf_ann)\n",
        "    pdiff = np.zeros((num_iter,1))\n",
        "    # -------------------------------------------\n",
        "    # Train SGD ANN (for comparison)\n",
        "    logging.info(\"Training neural net with SGD\")\n",
        "    info_tracker = EpochInfoTracker()\n",
        "    callbacks = [info_tracker]\n",
        "    history = sgd_ann.fit(params.X_data, params.y_data, batch_size=1, epochs=1, verbose=3,\n",
        "                          callbacks=callbacks)\n",
        "    logging.info('Training SGD complete')\n",
        "    # -------------------------------------------\n",
        "    # Training loop with UKF\n",
        "    out = StringIO()\n",
        "    sifnn=[]\n",
        "    logging.info(\"Training neural net with UKF\")\n",
        "    t0 = time.time()\n",
        "    epoch = 0\n",
        "    #num_iter = 10 #hack\n",
        "    minval = np.ones((num_iter,1))\n",
        "    aRate = 0.5\n",
        "    for i in range(num_iter):\n",
        "        #print(\"SHOUD\", mean_squared_error(z_true_series, ukf_ann.predict(params.X_data)))\n",
        "        idx = i % len(z_true_series)\n",
        "        # logging.info(idx)\n",
        "        if 0 == 0:\n",
        "            if not params.train_ukf_ann:\n",
        "                break\n",
        "\n",
        "            preds = ukf_ann.predict(params.X_data)\n",
        "            mse = mean_squared_error(z_true_series, preds)\n",
        "            ukf_train_mse[epoch] = mse\n",
        "            my_ukf_train_mse[epoch] = mse\n",
        "            sifnn.append(mse)\n",
        "            print(\"The MSE is: \", mse)\n",
        "            if mse <= 0.01 and i > 10:\n",
        "                thelast = i\n",
        "                break\n",
        "           # ukf_w[:, epoch] = x[:]\n",
        "            #my_ukf_w[:, epoch] = x[:]\n",
        "\n",
        "            epoch += 1\n",
        "            #logging.info('Epoch: {} / {}'.format(epoch, params.epochs))\n",
        "        \n",
        "        #-----------------Genetic Algorithm------------\n",
        "        geneticMSE = []\n",
        "        geneticWeights = []\n",
        "        for jj in range(100):\n",
        "            geneticWeights.append(get_weights_vector(ukf_ann))                              #Store the weights vector\n",
        "            geneticMSE.append(mse)                                                          #Store the MSE values\n",
        "            params.curr_idx = idx  # For use in hw() to fetch correct x_k sample            #\n",
        "            z = z_true_series[idx]\n",
        "        \n",
        "            ##################################################\n",
        "            # SIF Predicition Stage\n",
        "            # Learning Rate at 0.01\n",
        "            \n",
        "        # error = mean_squared_error(z_true_series, preds)\n",
        "        # gradient = x.T * error / preds.shape[0]\n",
        "        # w = w - eta * gradient\n",
        "        \n",
        "            #ukf_filter.predict()\n",
        "\n",
        "            #1*get_weights_vector(ukf_ann) + 0.01#ukf_filter.x # + 0.01 * w\n",
        "            \n",
        "            #print(\"WW  \", z_true_series.shape, x.shape)\n",
        "            #pdb.set_trace()\n",
        "            innov = z_true_series - np.reshape(ukf_ann.predict(params.X_data) , z_true_series.shape)\n",
        "            x = get_weights_vector(ukf_ann) +  aRate*np.sign(z_true_series[idx] - ukf_ann.predict(params.X_data)[idx])\n",
        "            #innov = z_true_series - np.dot(C,x)\n",
        "            #print(\"Innov \", innov)\n",
        "\n",
        "            ### Do something with delta \n",
        "\n",
        "            ############## CHANGE #################\n",
        "            for i in range(1, m):\n",
        "                #innovA[i] = sum(innov[i])/len(innov[i])\n",
        "                if (abs(innov[i])/delta[i ]) >= 1:\n",
        "                    sat[i][i] = 1\n",
        "                else:\n",
        "                    sat[i][i] = abs(innov[i])/delta[i ]\n",
        "            ######################\n",
        "\n",
        "            pinvC = np.linalg.pinv(C)\n",
        "            K = np.dot(pinvC, sat)\n",
        "            x = np.asarray([xx * random.uniform(0.001, 1) for xx in x])\n",
        "            #print(x.shape, K.shape, innovA.shape, x.shape, np.dot(K, innovA).shape)\n",
        "            was = np.reshape(np.dot(K, innov), x.shape)\n",
        "            x = x + was  # NEED TO CHECK THIS LINE\n",
        "\n",
        "\n",
        "            #print(\"Error \" ,z_true_series[idx] - ukf_ann.predict(params.X_data)[idx])\n",
        "            #print(\"ErrorA \" ,z_true_series[idx] - sgd_ann.predict(params.X_data)[idx])\n",
        "            \n",
        "            set_weights(params.hxw_model, x)\n",
        "            set_weights(ukf_ann, x)\n",
        "            preds = ukf_ann.predict(params.X_data)\n",
        "            mse = mean_squared_error(z_true_series, preds)\n",
        "            print(\"MSEN: \", mse)\n",
        "            minval[idx] = mse\n",
        "            pdiff[idx] = mse \n",
        "            #if mse <= 0.03:\n",
        "             #   break\n",
        "            #ukf_filter.x = x\n",
        "            print(type(preds))\n",
        "            geneticMSE.append(mse)\n",
        "            geneticWeights.append(x)            \n",
        "            print(geneticMSE)\n",
        "            \n",
        "            # Genetic Algorithm \n",
        "            if (jj == 99):\n",
        "                print(geneticMSE[geneticMSE.index(min(geneticMSE))])\n",
        "                \n",
        "                set_weights(ukf_ann,geneticWeights[geneticMSE.index(min(geneticMSE))])\n",
        "                preds = ukf_ann.predict(params.X_data) \n",
        "           #     print(\"Last Set: \", mean_squared_error(z_true_series, preds))\n",
        "                set_weights(ukf_ann,geneticWeights[geneticMSE.index(min(geneticMSE))])\n",
        "           #     print(\"jjj\",mean_squared_error(z_true_series, ukf_ann.predict(params.X_data) ))\n",
        "            \n",
        "        \n",
        "    time_to_train = time.time() - t0\n",
        "    logging.info('Training complete. time_to_train = {:.2f} sec, {:.2f} min'.format(\n",
        "        time_to_train, time_to_train / 60))\n",
        "\n",
        "\n",
        "    # -------------------------------------------\n",
        "    # Results analysis\n",
        "\n",
        "    # Visualize evolution of ANN weights\n",
        "    \n",
        "\n",
        "\n",
        "    # Visualize error curve (SGD vs UKF)\n",
        "    x_var = range(thelast+1)\n",
        "    hist = history.history['loss']\n",
        "    ukf_train_mse = np.array(sifnn)\n",
        "    #utility.plot(x_var, hist, xlabel='Epoch',\n",
        "     #            label='SGD ANN training history (MSE)')\n",
        "    utility.plot(x_var, ukf_train_mse, new_figure=False,\n",
        "                 label='SIF ANN training history (MSE)')\n",
        "\n",
        "    # True test series vs. ANN pred vs, UKF pred\n",
        "    logging.info('Evaluating and visualizing neural net predictions')\n",
        "    evaluate_neural_nets(sgd_ann, ukf_ann, window,\n",
        "                         use_train_series=True, train_series=X_series)\n",
        "    evaluate_neural_nets(sgd_ann, ukf_ann, window)\n",
        "\n",
        "    utility.save_all_figures('output')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"The Min MSE is \", min(minval), \" vs \", hist[-1])\n",
        "    print(\"Total amount of epochs for SIF: \", epoch)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "   # os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # This line disables GPU\n",
        "    main()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2770576, 0.09736053442770576, 0.463717554277578, 0.463717554277578, 0.034950914021154314, 0.034950914021154314, 0.3689584718835318]\n",
            "MSEN:  0.08380265229128894\n",
            "<class 'numpy.ndarray'>\n",
            "[0.012003143119505613, 0.1854308911609561, 0.1854308911609561, 0.13052547011912902, 0.13052547011912902, 0.10728276428833587, 0.10728276428833587, 0.24590184949222146, 0.24590184949222146, 0.07624918023336352, 0.07624918023336352, 0.3481386606725477, 0.3481386606725477, 0.07809821097722099, 0.07809821097722099, 0.38815287502971524, 0.38815287502971524, 0.07531691315607641, 0.07531691315607641, 0.2693680025797388, 0.2693680025797388, 0.08162621676202633, 0.08162621676202633, 0.21398765714109305, 0.21398765714109305, 0.08844516006728402, 0.08844516006728402, 0.3807956873919455, 0.3807956873919455, 0.07204983303947894, 0.07204983303947894, 0.3254161191341169, 0.3254161191341169, 0.08539286990665225, 0.08539286990665225, 0.27649057017233364, 0.27649057017233364, 0.10080306419523306, 0.10080306419523306, 0.3477665520211895, 0.3477665520211895, 0.10284792256153821, 0.10284792256153821, 0.5387072450301775, 0.5387072450301775, 0.05959691481357304, 0.05959691481357304, 0.44519202019986787, 0.44519202019986787, 0.03917685181867873, 0.03917685181867873, 0.41285139532255394, 0.41285139532255394, 0.030700986181332966, 0.030700986181332966, 0.4499851754098501, 0.4499851754098501, 0.03282731928427962, 0.03282731928427962, 0.5159292402250676, 0.5159292402250676, 0.023893617352534133, 0.023893617352534133, 0.4626364336583967, 0.4626364336583967, 0.07625020829347635, 0.07625020829347635, 0.3930145597484547, 0.3930145597484547, 0.06451640229543265, 0.06451640229543265, 0.3952841294215066, 0.3952841294215066, 0.04613699390305432, 0.04613699390305432, 0.3923685320113864, 0.3923685320113864, 0.06798626084539959, 0.06798626084539959, 0.32931750151691946, 0.32931750151691946, 0.05988276201048654, 0.05988276201048654, 0.3690551064246649, 0.3690551064246649, 0.08138718346047645, 0.08138718346047645, 0.28837979577453604, 0.28837979577453604, 0.06757315288904187, 0.06757315288904187, 0.34467832966018475, 0.34467832966018475, 0.0588991902620646, 0.0588991902620646, 0.4046681684880672, 0.4046681684880672, 0.04514999861012953, 0.04514999861012953, 0.3192384088364962, 0.3192384088364962, 0.0645200448880465, 0.0645200448880465, 0.301286283506777, 0.301286283506777, 0.12006077205914448, 0.12006077205914448, 0.38098133069980367, 0.38098133069980367, 0.07275200464359265, 0.07275200464359265, 0.20823213847015598, 0.20823213847015598, 0.06399425005163469, 0.06399425005163469, 0.37703058795157673, 0.37703058795157673, 0.074306960002153, 0.074306960002153, 0.3695459541382034, 0.3695459541382034, 0.04015555255920204, 0.04015555255920204, 0.3734453012188893, 0.3734453012188893, 0.03389689025571368, 0.03389689025571368, 0.35103913134324466, 0.35103913134324466, 0.04666115321352271, 0.04666115321352271, 0.3713171379591451, 0.3713171379591451, 0.06988427302647612, 0.06988427302647612, 0.3802309633471954, 0.3802309633471954, 0.12162590192768465, 0.12162590192768465, 0.39698144423118537, 0.39698144423118537, 0.06512328984770464, 0.06512328984770464, 0.30529136801474915, 0.30529136801474915, 0.056477091400785696, 0.056477091400785696, 0.5355580783627083, 0.5355580783627083, 0.0741131971899058, 0.0741131971899058, 0.43971241748088497, 0.43971241748088497, 0.047048722510411575, 0.047048722510411575, 0.2747977562380379, 0.2747977562380379, 0.0815250954947946, 0.0815250954947946, 0.2691687320582973, 0.2691687320582973, 0.03713245863936509, 0.03713245863936509, 0.46005251943482295, 0.46005251943482295, 0.08373087543158862, 0.08373087543158862, 0.38634206295464346, 0.38634206295464346, 0.04397851261522899, 0.04397851261522899, 0.38651266503483356, 0.38651266503483356, 0.0583873970778011, 0.0583873970778011, 0.37966135822621927, 0.37966135822621927, 0.06010627107347014, 0.06010627107347014, 0.3376106111297223, 0.3376106111297223, 0.08222994825169243, 0.08222994825169243, 0.3846685925725519, 0.3846685925725519, 0.09736053442770576, 0.09736053442770576, 0.463717554277578, 0.463717554277578, 0.034950914021154314, 0.034950914021154314, 0.3689584718835318, 0.3689584718835318, 0.08380265229128894]\n",
            "MSEN:  0.3643353945217627\n",
            "<class 'numpy.ndarray'>\n",
            "[0.012003143119505613, 0.1854308911609561, 0.1854308911609561, 0.13052547011912902, 0.13052547011912902, 0.10728276428833587, 0.10728276428833587, 0.24590184949222146, 0.24590184949222146, 0.07624918023336352, 0.07624918023336352, 0.3481386606725477, 0.3481386606725477, 0.07809821097722099, 0.07809821097722099, 0.38815287502971524, 0.38815287502971524, 0.07531691315607641, 0.07531691315607641, 0.2693680025797388, 0.2693680025797388, 0.08162621676202633, 0.08162621676202633, 0.21398765714109305, 0.21398765714109305, 0.08844516006728402, 0.08844516006728402, 0.3807956873919455, 0.3807956873919455, 0.07204983303947894, 0.07204983303947894, 0.3254161191341169, 0.3254161191341169, 0.08539286990665225, 0.08539286990665225, 0.27649057017233364, 0.27649057017233364, 0.10080306419523306, 0.10080306419523306, 0.3477665520211895, 0.3477665520211895, 0.10284792256153821, 0.10284792256153821, 0.5387072450301775, 0.5387072450301775, 0.05959691481357304, 0.05959691481357304, 0.44519202019986787, 0.44519202019986787, 0.03917685181867873, 0.03917685181867873, 0.41285139532255394, 0.41285139532255394, 0.030700986181332966, 0.030700986181332966, 0.4499851754098501, 0.4499851754098501, 0.03282731928427962, 0.03282731928427962, 0.5159292402250676, 0.5159292402250676, 0.023893617352534133, 0.023893617352534133, 0.4626364336583967, 0.4626364336583967, 0.07625020829347635, 0.07625020829347635, 0.3930145597484547, 0.3930145597484547, 0.06451640229543265, 0.06451640229543265, 0.3952841294215066, 0.3952841294215066, 0.04613699390305432, 0.04613699390305432, 0.3923685320113864, 0.3923685320113864, 0.06798626084539959, 0.06798626084539959, 0.32931750151691946, 0.32931750151691946, 0.05988276201048654, 0.05988276201048654, 0.3690551064246649, 0.3690551064246649, 0.08138718346047645, 0.08138718346047645, 0.28837979577453604, 0.28837979577453604, 0.06757315288904187, 0.06757315288904187, 0.34467832966018475, 0.34467832966018475, 0.0588991902620646, 0.0588991902620646, 0.4046681684880672, 0.4046681684880672, 0.04514999861012953, 0.04514999861012953, 0.3192384088364962, 0.3192384088364962, 0.0645200448880465, 0.0645200448880465, 0.301286283506777, 0.301286283506777, 0.12006077205914448, 0.12006077205914448, 0.38098133069980367, 0.38098133069980367, 0.07275200464359265, 0.07275200464359265, 0.20823213847015598, 0.20823213847015598, 0.06399425005163469, 0.06399425005163469, 0.37703058795157673, 0.37703058795157673, 0.074306960002153, 0.074306960002153, 0.3695459541382034, 0.3695459541382034, 0.04015555255920204, 0.04015555255920204, 0.3734453012188893, 0.3734453012188893, 0.03389689025571368, 0.03389689025571368, 0.35103913134324466, 0.35103913134324466, 0.04666115321352271, 0.04666115321352271, 0.3713171379591451, 0.3713171379591451, 0.06988427302647612, 0.06988427302647612, 0.3802309633471954, 0.3802309633471954, 0.12162590192768465, 0.12162590192768465, 0.39698144423118537, 0.39698144423118537, 0.06512328984770464, 0.06512328984770464, 0.30529136801474915, 0.30529136801474915, 0.056477091400785696, 0.056477091400785696, 0.5355580783627083, 0.5355580783627083, 0.0741131971899058, 0.0741131971899058, 0.43971241748088497, 0.43971241748088497, 0.047048722510411575, 0.047048722510411575, 0.2747977562380379, 0.2747977562380379, 0.0815250954947946, 0.0815250954947946, 0.2691687320582973, 0.2691687320582973, 0.03713245863936509, 0.03713245863936509, 0.46005251943482295, 0.46005251943482295, 0.08373087543158862, 0.08373087543158862, 0.38634206295464346, 0.38634206295464346, 0.04397851261522899, 0.04397851261522899, 0.38651266503483356, 0.38651266503483356, 0.0583873970778011, 0.0583873970778011, 0.37966135822621927, 0.37966135822621927, 0.06010627107347014, 0.06010627107347014, 0.3376106111297223, 0.3376106111297223, 0.08222994825169243, 0.08222994825169243, 0.3846685925725519, 0.3846685925725519, 0.09736053442770576, 0.09736053442770576, 0.463717554277578, 0.463717554277578, 0.034950914021154314, 0.034950914021154314, 0.3689584718835318, 0.3689584718835318, 0.08380265229128894, 0.08380265229128894, 0.3643353945217627]\n",
            "MSEN:  0.08610257219456799\n",
            "<class 'numpy.ndarray'>\n",
            "[0.012003143119505613, 0.1854308911609561, 0.1854308911609561, 0.13052547011912902, 0.13052547011912902, 0.10728276428833587, 0.10728276428833587, 0.24590184949222146, 0.24590184949222146, 0.07624918023336352, 0.07624918023336352, 0.3481386606725477, 0.3481386606725477, 0.07809821097722099, 0.07809821097722099, 0.38815287502971524, 0.38815287502971524, 0.07531691315607641, 0.07531691315607641, 0.2693680025797388, 0.2693680025797388, 0.08162621676202633, 0.08162621676202633, 0.21398765714109305, 0.21398765714109305, 0.08844516006728402, 0.08844516006728402, 0.3807956873919455, 0.3807956873919455, 0.07204983303947894, 0.07204983303947894, 0.3254161191341169, 0.3254161191341169, 0.08539286990665225, 0.08539286990665225, 0.27649057017233364, 0.27649057017233364, 0.10080306419523306, 0.10080306419523306, 0.3477665520211895, 0.3477665520211895, 0.10284792256153821, 0.10284792256153821, 0.5387072450301775, 0.5387072450301775, 0.05959691481357304, 0.05959691481357304, 0.44519202019986787, 0.44519202019986787, 0.03917685181867873, 0.03917685181867873, 0.41285139532255394, 0.41285139532255394, 0.030700986181332966, 0.030700986181332966, 0.4499851754098501, 0.4499851754098501, 0.03282731928427962, 0.03282731928427962, 0.5159292402250676, 0.5159292402250676, 0.023893617352534133, 0.023893617352534133, 0.4626364336583967, 0.4626364336583967, 0.07625020829347635, 0.07625020829347635, 0.3930145597484547, 0.3930145597484547, 0.06451640229543265, 0.06451640229543265, 0.3952841294215066, 0.3952841294215066, 0.04613699390305432, 0.04613699390305432, 0.3923685320113864, 0.3923685320113864, 0.06798626084539959, 0.06798626084539959, 0.32931750151691946, 0.32931750151691946, 0.05988276201048654, 0.05988276201048654, 0.3690551064246649, 0.3690551064246649, 0.08138718346047645, 0.08138718346047645, 0.28837979577453604, 0.28837979577453604, 0.06757315288904187, 0.06757315288904187, 0.34467832966018475, 0.34467832966018475, 0.0588991902620646, 0.0588991902620646, 0.4046681684880672, 0.4046681684880672, 0.04514999861012953, 0.04514999861012953, 0.3192384088364962, 0.3192384088364962, 0.0645200448880465, 0.0645200448880465, 0.301286283506777, 0.301286283506777, 0.12006077205914448, 0.12006077205914448, 0.38098133069980367, 0.38098133069980367, 0.07275200464359265, 0.07275200464359265, 0.20823213847015598, 0.20823213847015598, 0.06399425005163469, 0.06399425005163469, 0.37703058795157673, 0.37703058795157673, 0.074306960002153, 0.074306960002153, 0.3695459541382034, 0.3695459541382034, 0.04015555255920204, 0.04015555255920204, 0.3734453012188893, 0.3734453012188893, 0.03389689025571368, 0.03389689025571368, 0.35103913134324466, 0.35103913134324466, 0.04666115321352271, 0.04666115321352271, 0.3713171379591451, 0.3713171379591451, 0.06988427302647612, 0.06988427302647612, 0.3802309633471954, 0.3802309633471954, 0.12162590192768465, 0.12162590192768465, 0.39698144423118537, 0.39698144423118537, 0.06512328984770464, 0.06512328984770464, 0.30529136801474915, 0.30529136801474915, 0.056477091400785696, 0.056477091400785696, 0.5355580783627083, 0.5355580783627083, 0.0741131971899058, 0.0741131971899058, 0.43971241748088497, 0.43971241748088497, 0.047048722510411575, 0.047048722510411575, 0.2747977562380379, 0.2747977562380379, 0.0815250954947946, 0.0815250954947946, 0.2691687320582973, 0.2691687320582973, 0.03713245863936509, 0.03713245863936509, 0.46005251943482295, 0.46005251943482295, 0.08373087543158862, 0.08373087543158862, 0.38634206295464346, 0.38634206295464346, 0.04397851261522899, 0.04397851261522899, 0.38651266503483356, 0.38651266503483356, 0.0583873970778011, 0.0583873970778011, 0.37966135822621927, 0.37966135822621927, 0.06010627107347014, 0.06010627107347014, 0.3376106111297223, 0.3376106111297223, 0.08222994825169243, 0.08222994825169243, 0.3846685925725519, 0.3846685925725519, 0.09736053442770576, 0.09736053442770576, 0.463717554277578, 0.463717554277578, 0.034950914021154314, 0.034950914021154314, 0.3689584718835318, 0.3689584718835318, 0.08380265229128894, 0.08380265229128894, 0.3643353945217627, 0.3643353945217627, 0.08610257219456799]\n",
            "MSEN:  0.4218515605043865\n",
            "<class 'numpy.ndarray'>\n",
            "[0.012003143119505613, 0.1854308911609561, 0.1854308911609561, 0.13052547011912902, 0.13052547011912902, 0.10728276428833587, 0.10728276428833587, 0.24590184949222146, 0.24590184949222146, 0.07624918023336352, 0.07624918023336352, 0.3481386606725477, 0.3481386606725477, 0.07809821097722099, 0.07809821097722099, 0.38815287502971524, 0.38815287502971524, 0.07531691315607641, 0.07531691315607641, 0.2693680025797388, 0.2693680025797388, 0.08162621676202633, 0.08162621676202633, 0.21398765714109305, 0.21398765714109305, 0.08844516006728402, 0.08844516006728402, 0.3807956873919455, 0.3807956873919455, 0.07204983303947894, 0.07204983303947894, 0.3254161191341169, 0.3254161191341169, 0.08539286990665225, 0.08539286990665225, 0.27649057017233364, 0.27649057017233364, 0.10080306419523306, 0.10080306419523306, 0.3477665520211895, 0.3477665520211895, 0.10284792256153821, 0.10284792256153821, 0.5387072450301775, 0.5387072450301775, 0.05959691481357304, 0.05959691481357304, 0.44519202019986787, 0.44519202019986787, 0.03917685181867873, 0.03917685181867873, 0.41285139532255394, 0.41285139532255394, 0.030700986181332966, 0.030700986181332966, 0.4499851754098501, 0.4499851754098501, 0.03282731928427962, 0.03282731928427962, 0.5159292402250676, 0.5159292402250676, 0.023893617352534133, 0.023893617352534133, 0.4626364336583967, 0.4626364336583967, 0.07625020829347635, 0.07625020829347635, 0.3930145597484547, 0.3930145597484547, 0.06451640229543265, 0.06451640229543265, 0.3952841294215066, 0.3952841294215066, 0.04613699390305432, 0.04613699390305432, 0.3923685320113864, 0.3923685320113864, 0.06798626084539959, 0.06798626084539959, 0.32931750151691946, 0.32931750151691946, 0.05988276201048654, 0.05988276201048654, 0.3690551064246649, 0.3690551064246649, 0.08138718346047645, 0.08138718346047645, 0.28837979577453604, 0.28837979577453604, 0.06757315288904187, 0.06757315288904187, 0.34467832966018475, 0.34467832966018475, 0.0588991902620646, 0.0588991902620646, 0.4046681684880672, 0.4046681684880672, 0.04514999861012953, 0.04514999861012953, 0.3192384088364962, 0.3192384088364962, 0.0645200448880465, 0.0645200448880465, 0.301286283506777, 0.301286283506777, 0.12006077205914448, 0.12006077205914448, 0.38098133069980367, 0.38098133069980367, 0.07275200464359265, 0.07275200464359265, 0.20823213847015598, 0.20823213847015598, 0.06399425005163469, 0.06399425005163469, 0.37703058795157673, 0.37703058795157673, 0.074306960002153, 0.074306960002153, 0.3695459541382034, 0.3695459541382034, 0.04015555255920204, 0.04015555255920204, 0.3734453012188893, 0.3734453012188893, 0.03389689025571368, 0.03389689025571368, 0.35103913134324466, 0.35103913134324466, 0.04666115321352271, 0.04666115321352271, 0.3713171379591451, 0.3713171379591451, 0.06988427302647612, 0.06988427302647612, 0.3802309633471954, 0.3802309633471954, 0.12162590192768465, 0.12162590192768465, 0.39698144423118537, 0.39698144423118537, 0.06512328984770464, 0.06512328984770464, 0.30529136801474915, 0.30529136801474915, 0.056477091400785696, 0.056477091400785696, 0.5355580783627083, 0.5355580783627083, 0.0741131971899058, 0.0741131971899058, 0.43971241748088497, 0.43971241748088497, 0.047048722510411575, 0.047048722510411575, 0.2747977562380379, 0.2747977562380379, 0.0815250954947946, 0.0815250954947946, 0.2691687320582973, 0.2691687320582973, 0.03713245863936509, 0.03713245863936509, 0.46005251943482295, 0.46005251943482295, 0.08373087543158862, 0.08373087543158862, 0.38634206295464346, 0.38634206295464346, 0.04397851261522899, 0.04397851261522899, 0.38651266503483356, 0.38651266503483356, 0.0583873970778011, 0.0583873970778011, 0.37966135822621927, 0.37966135822621927, 0.06010627107347014, 0.06010627107347014, 0.3376106111297223, 0.3376106111297223, 0.08222994825169243, 0.08222994825169243, 0.3846685925725519, 0.3846685925725519, 0.09736053442770576, 0.09736053442770576, 0.463717554277578, 0.463717554277578, 0.034950914021154314, 0.034950914021154314, 0.3689584718835318, 0.3689584718835318, 0.08380265229128894, 0.08380265229128894, 0.3643353945217627, 0.3643353945217627, 0.08610257219456799, 0.08610257219456799, 0.4218515605043865]\n",
            "0.012003143119505613\n",
            "The MSE is:  0.012003143119505613\n",
            "MSEN:  0.15976304926436422\n",
            "<class 'numpy.ndarray'>\n",
            "[0.012003143119505613, 0.15976304926436422]\n",
            "MSEN:  0.21345253372962833\n",
            "<class 'numpy.ndarray'>\n",
            "[0.012003143119505613, 0.15976304926436422, 0.15976304926436422, 0.21345253372962833]\n",
            "MSEN:  0.12424157933579069\n",
            "<class 'numpy.ndarray'>\n",
            "[0.012003143119505613, 0.15976304926436422, 0.15976304926436422, 0.21345253372962833, 0.21345253372962833, 0.12424157933579069]\n",
            "MSEN:  0.447101664696894\n",
            "<class 'numpy.ndarray'>\n",
            "[0.012003143119505613, 0.15976304926436422, 0.15976304926436422, 0.21345253372962833, 0.21345253372962833, 0.12424157933579069, 0.12424157933579069, 0.447101664696894]\n",
            "MSEN:  0.12068376264704293\n",
            "<class 'numpy.ndarray'>\n",
            "[0.012003143119505613, 0.15976304926436422, 0.15976304926436422, 0.21345253372962833, 0.21345253372962833, 0.12424157933579069, 0.12424157933579069, 0.447101664696894, 0.447101664696894, 0.12068376264704293]\n",
            "MSEN:  0.34108184513655004\n",
            "<class 'numpy.ndarray'>\n",
            "[0.012003143119505613, 0.15976304926436422, 0.15976304926436422, 0.21345253372962833, 0.21345253372962833, 0.12424157933579069, 0.12424157933579069, 0.447101664696894, 0.447101664696894, 0.12068376264704293, 0.12068376264704293, 0.34108184513655004]\n",
            "MSEN:  0.07586784621977095\n",
            "<class 'numpy.ndarray'>\n",
            "[0.012003143119505613, 0.15976304926436422, 0.15976304926436422, 0.21345253372962833, 0.21345253372962833, 0.12424157933579069, 0.12424157933579069, 0.447101664696894, 0.447101664696894, 0.12068376264704293, 0.12068376264704293, 0.34108184513655004, 0.34108184513655004, 0.07586784621977095]\n",
            "MSEN:  0.3616910958835877\n",
            "<class 'numpy.ndarray'>\n",
            "[0.012003143119505613, 0.15976304926436422, 0.15976304926436422, 0.21345253372962833, 0.21345253372962833, 0.12424157933579069, 0.12424157933579069, 0.447101664696894, 0.447101664696894, 0.12068376264704293, 0.12068376264704293, 0.34108184513655004, 0.34108184513655004, 0.07586784621977095, 0.07586784621977095, 0.3616910958835877]\n",
            "MSEN:  0.029688263538408307\n",
            "<class 'numpy.ndarray'>\n",
            "[0.012003143119505613, 0.15976304926436422, 0.15976304926436422, 0.21345253372962833, 0.21345253372962833, 0.12424157933579069, 0.12424157933579069, 0.447101664696894, 0.447101664696894, 0.12068376264704293, 0.12068376264704293, 0.34108184513655004, 0.34108184513655004, 0.07586784621977095, 0.07586784621977095, 0.3616910958835877, 0.3616910958835877, 0.029688263538408307]\n",
            "MSEN:  0.3561034013699309\n",
            "<class 'numpy.ndarray'>\n",
            "[0.012003143119505613, 0.15976304926436422, 0.15976304926436422, 0.21345253372962833, 0.21345253372962833, 0.12424157933579069, 0.12424157933579069, 0.447101664696894, 0.447101664696894, 0.12068376264704293, 0.12068376264704293, 0.34108184513655004, 0.34108184513655004, 0.07586784621977095, 0.07586784621977095, 0.3616910958835877, 0.3616910958835877, 0.029688263538408307, 0.029688263538408307, 0.3561034013699309]\n",
            "MSEN:  0.08295250605574003\n",
            "<class 'numpy.ndarray'>\n",
            "[0.012003143119505613, 0.15976304926436422, 0.15976304926436422, 0.21345253372962833, 0.21345253372962833, 0.12424157933579069, 0.12424157933579069, 0.447101664696894, 0.447101664696894, 0.12068376264704293, 0.12068376264704293, 0.34108184513655004, 0.34108184513655004, 0.07586784621977095, 0.07586784621977095, 0.3616910958835877, 0.3616910958835877, 0.029688263538408307, 0.029688263538408307, 0.3561034013699309, 0.3561034013699309, 0.08295250605574003]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-65b6cda2cfbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m    \u001b[0;31m# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # This line disables GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-65b6cda2cfbf>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;31m#pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0minnov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz_true_series\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mukf_ann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mz_true_series\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_weights_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mukf_ann\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0maRate\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_true_series\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mukf_ann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0;31m#innov = z_true_series - np.dot(C,x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;31m#print(\"Innov \", innov)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1623\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m       \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1625\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1626\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    680\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    703\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 705\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m       \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   2970\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 2972\u001b[0;31m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0m\u001b[1;32m   2973\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNJOdA6cOJ5W"
      },
      "source": [
        "xx , yy = params.X_data, params.y_data "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iay1yMX3oGj1"
      },
      "source": [
        "!zip -r output.zip output/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}